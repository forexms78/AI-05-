{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMAKzxIdq8bTglU9Rui+bPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forexms78/AI-05-/blob/main/%ED%85%90%EC%84%9C_%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. 텐서만들기\n"
      ],
      "metadata": {
        "id": "FGOj-HidosuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 임포트할 때 파이토치가 아니라 그냥 토치라고 써야 합니다.\n",
        "import torch"
      ],
      "metadata": {
        "id": "EoILFzKcp_hv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python 리스트를 PyTorch 텐서로 변환하려면 torch.tensor() 함수를 사용합니다."
      ],
      "metadata": {
        "id": "Suoa4ntCGkMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = [1, 2]\n",
        "\n",
        "tensor = torch.tensor(data_list)\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs8GN-2xsh9i",
        "outputId": "3c803651-73cf-48b6-96a8-5a63906e412b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyPQU4uVsxAM",
        "outputId": "4b00a0fb-b1de-4235-835f-b6bb7c5aa0b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "변환된 텐서는 리스트와 동일한 값을 가지며, tensor() 함수를 통해 PyTorch의 텐서 객체로 만들어집니다"
      ],
      "metadata": {
        "id": "rMZJQoKlGoAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성한 텐서의 정보를 확인하려면 텐서 객체의 속성과 메서드를 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "JtmAouSsGtuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'data type: {tensor.dtype}') # 텐서의 데이터 타입\n",
        "print(f'number of dimensions: {tensor.ndim}')\n",
        "print(f'shape: {tensor.shape}') # 텐서의 차원\n",
        "print(f'device: {tensor.device}') # 텐서가 할당된 장치(cpu/gpu)\n",
        "print(f'requires_grad: {tensor.requires_grad}') # 자동 미분을 기록할 지 여부"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_Fe5rY6s1Ze",
        "outputId": "cc8d42fe-69b6-4e91-957f-f4554a9f848a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data type: torch.int64\n",
            "number of dimensions: 1\n",
            "shape: torch.Size([2])\n",
            "device: cpu\n",
            "requires_grad: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shape 속성 외에도 size() 메서드를 사용하여 텐서의 형태를 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "ix6he9YwGwX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'size: {tensor.size()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK6BkT9ntFu2",
        "outputId": "3a1c0cf0-a5bc-4dda-8db4-8d3ef47d8c3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size: torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy 배열에서 텐서를 생성하는 세 가지 방법이 있습니다."
      ],
      "metadata": {
        "id": "e1B8zUsQG2wI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 방법 1 : torch.tensor()\n",
        "\n",
        "data_np = np.array(\n",
        "    [\n",
        "        [1, 2],\n",
        "        [3, 4]\n",
        "    ]\n",
        ")\n",
        "\n",
        "tensor_np = torch.tensor(data_np)\n",
        "tensor_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf9G7-2ktVYu",
        "outputId": "b203e52b-ca3a-4bcd-c74f-0630f9e06a26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 방법 2 : torch.from_numpy()\n",
        "\n",
        "tensor_from_numpy = torch.from_numpy(data_np)\n",
        "tensor_from_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taizRKsUtwxr",
        "outputId": "5f961a29-809a-424c-8fb9-e712c473549d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 방법 3 : torch.as_tensor()\n",
        "\n",
        "tensor_as_tensor = torch.as_tensor(data_np)\n",
        "tensor_as_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rtIcdPFYcez",
        "outputId": "56b82866-2090-4ef1-d40d-b9613c955ebf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_np[0, 0] = -1\n",
        "\n",
        "print(f'torch.tensor() result\\n{tensor_np}\\n')\n",
        "print(f'torch.from_numpy() result\\n{tensor_from_numpy}')\n",
        "print(f'torch.as_tensor() result\\n{tensor_as_tensor}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrjrpnsbuIpU",
        "outputId": "83f89c3a-3ec6-4ab5-bb19-f0458671dfea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.tensor() result\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "\n",
            "torch.from_numpy() result\n",
            "tensor([[-1,  2],\n",
            "        [ 3,  4]])\n",
            "torch.as_tensor() result\n",
            "tensor([[-1,  2],\n",
            "        [ 3,  4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torch.tensor : 넘파이 배열의 데이터를 복사하여 텐서 생성 -> 메모리 공유 X\n",
        "- torch.from_numpy : 넘파이 배열과 메모리 공유 -> 원본 배열 변경 되면 텐서도 변경됨, 넘파이 배열만 입력으로 허용됨\n",
        "- torch.as_tensor : 메모리 공유 O, 다른 파이썬 객체에도 사용가능"
      ],
      "metadata": {
        "id": "oAh2axVhHFoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_as_tensor2 = torch.from_numpy([[1, 2], [3, 4]])\n",
        "torch_as_tensor2\n",
        "\n",
        "# 파이썬 배열만으로 입력받아서 오류가 나타남 무조건 numpy배열로 받아야함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "T9AijILzY7HN",
        "outputId": "7a555a4d-613e-472a-dbe7-d10dc0abb212"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected np.ndarray (got list)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3552594942.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch_as_tensor2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch_as_tensor2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 파이썬 배열만으로 입력받아서 오류가 나타남 무조건 numpy배열로 받아야함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got list)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_as_tensor2 = torch.as_tensor([[1, 2], [3, 4]])\n",
        "torch_as_tensor2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9tb25sgYy5q",
        "outputId": "15d2befc-3e5d-4b3e-9095-66488e5c7545"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 타입 지정하기"
      ],
      "metadata": {
        "id": "YaY4TBI2HVCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch 텐서는 숫자로 구성된 다차원 배열이며, 텐서 내 모든 숫자는 동일한 데이터 타입을 가집니다. 기본 정수 타입은 torch.int64, 기본 실수 타입은 torch.float32입니다."
      ],
      "metadata": {
        "id": "00r95vaCHYr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.dtype)\n",
        "print(tensor_np.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4-3PT9LunYj",
        "outputId": "355f15e7-5b79-43e8-8021-982998618169"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 1.5])\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NavjGQs_u44b",
        "outputId": "b586b83b-347f-4033-f1d4-c5e2f913dee1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dtype 매개변수를 사용하여 텐서의 데이터 타입을 명시적으로 설정할 수 있습니다."
      ],
      "metadata": {
        "id": "f4Kl8mMbHcko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHOhvPE1vNet",
        "outputId": "8198829d-3e10-469c-bfce-c8e13aa08c1c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 타입 변환하기"
      ],
      "metadata": {
        "id": "kGlXsJGoJOsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.to()` 메서드 사용하기 : to() 메서드는 PyTorch에서 가장 일반적으로 사용되는 방식입니다. 장치(Device) 전환과 데이터 타입 변경 모두에 사용 가능합니다.\n"
      ],
      "metadata": {
        "id": "eJeUfz_rJSjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float 텐서를 정수형으로 변환\n",
        "tensor = torch.tensor([1.2, 3.4, 5.6], dtype=torch.float32)\n",
        "int_tensor = tensor.to(torch.int32)\n",
        "\n",
        "print(int_tensor)  # tensor([1, 3, 5], dtype=torch.int32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkywdhtBJZLX",
        "outputId": "ddb131fb-7ea7-413e-b4c5-44214d031bab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 3, 5], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvrZ_ZIlLfmD",
        "outputId": "83ac7467-24a7-4958-c08e-2bfff06d5e65"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 타입을 int로 변경하며 GPU로 이동\n",
        "gpu_int_tensor = tensor.to(dtype=torch.int32, device=\"cuda\")\n",
        "print(gpu_int_tensor)  # Output: cuda:0\n"
      ],
      "metadata": {
        "id": "-IhD-xmBLX3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee92b5c-360a-4f74-8820-2a05848ea8ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 3, 5], device='cuda:0', dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " `.float()`, `.int()`, `.long()` 등 메서드 사용\n",
        "\n",
        "PyTorch는 데이터 타입별로 빠르게 변환할 수 있는 메서드를 제공합니다."
      ],
      "metadata": {
        "id": "tYggZ2DdJn9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float -> Int\n",
        "int_tensor = tensor.int()\n",
        "\n",
        "# Float -> Long(64bit 정수형 데이터 // 큰 정수를 다룰 때 사용 // 인덱싱, 범주형 데이터 처리, 라벨 등)\n",
        "long_tensor = tensor.long()\n",
        "\n",
        "# Float -> Double\n",
        "double_tensor = tensor.double()\n",
        "\n",
        "print(int_tensor)  # tensor([1, 3, 5], dtype=torch.int32)\n",
        "print(long_tensor)  # tensor([1, 3, 5], dtype=torch.int64)\n",
        "print(double_tensor)  # tensor([1.2000, 3.4000, 5.6000], dtype=torch.float64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfrA2lWoJZGo",
        "outputId": "ad58b37f-0dbe-4d3a-8dd2-6bdcfb9cfcf8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 3, 5], dtype=torch.int32)\n",
            "tensor([1, 3, 5])\n",
            "tensor([1.2000, 3.4000, 5.6000], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "long_tensor[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWG2kEdWHeUU",
        "outputId": "0cafc166-62b8-49e5-9b6c-8860f89b1f42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **권장:** `.to(torch.<dtype>)` 방식.\n",
        "- **빠르게 변환하려면:** `.float()`, `.int()`, `.long()` 등 사용.\n",
        "\n",
        "데이터 타입을 변환할 때 `.to()` 메서드가 가장 유연하고 직관적입니다."
      ],
      "metadata": {
        "id": "bZhl2VT9LSmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. 특수한 텐서 생성 함수"
      ],
      "metadata": {
        "id": "ExI9rvyKo25v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch를 사용하다 보면 특수한 텐서를 만들어야 할 때가 생깁니다. 예를 들어 모든 값을 랜덤하게 초기화할 수도 있고요. 텐서의 모든 값을 0이나 1로 만들 때도 있죠. 이런 경우에 사용할 수 있는 함수를 몇 가지 살펴봅시다."
      ],
      "metadata": {
        "id": "nFuLqiZ4LktS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 랜덤한 값으로 만들기\n",
        "\n",
        "랜덤한 값으로 텐서를 만드는 가장 대표적인 함수는 `rand()`입니다. 원하는 형태를 입력하면 0과 1 사이의 균등 분포를 바탕으로 난수 텐서가 만들어져요. 텐서 형태는 콤마로 숫자를 구분하여 입력해도 되고, 리스트나 튜플로 모아서 입력해도 됩니다."
      ],
      "metadata": {
        "id": "UA8Hv4QjLnbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 난수 텐서\n",
        "\n",
        "torch.rand(2, 3)\n",
        "torch.rand([2, 3])\n",
        "torch.rand((2, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS_PUuvdozjq",
        "outputId": "39449a9b-7ac9-404c-acb3-49822dc2b500"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7229, 0.7062, 0.3931],\n",
              "        [0.2585, 0.4954, 0.3198]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 min_val과 max_val 사이의 균등 분포에서 값을 추출하고 싶다면 이런 식으로 rand() 함수 결과를 변환해 주세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "A93KnC1WpGbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_val, max_val = 0, 10\n",
        "min_val + (max_val - min_val) * torch.rand(2, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4790xTW7o9EO",
        "outputId": "d5d99217-6ccd-4e03-d7d5-42e386885df6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.1924, 0.6591, 8.5480],\n",
              "        [5.5443, 1.9930, 1.1603]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "또 다른 함수로는 randn()이 있습니다. 원하는 형태를 입력하면 평균이 0, 표준편차가 1인 표준 정규 분포를 바탕으로 난수 텐서가 만들어져요.\n",
        "\n"
      ],
      "metadata": {
        "id": "5tUJIm-opISk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(2, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZdxSI7kpMo3",
        "outputId": "f941467f-89a3-4083-cef0-a954b0ef62d8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2105,  0.8074,  0.8401],\n",
              "        [-0.6186,  1.4235,  0.6025]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 평균 mu,  표준편차 sigma인 정규 분포를 활용하고 싶다면 이런 식으로 randn() 함수 결과를 변환해야 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "laFeJLG3pQng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu, sigma = 1, 10\n",
        "mu + sigma * torch.randn(2, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODrr47s6pOhc",
        "outputId": "55a40219-bd9d-4bc4-f244-59f9360b8aad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.1802, -5.7549,  1.8099],\n",
              "        [10.1006, -7.1346,  0.0920]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 특정한 값으로 만들기"
      ],
      "metadata": {
        "id": "4BuWlob9LyEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "zeros() 함수에 원하는 형태를 입력하면 값이 전부 0인 텐서를 만들 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "LEVr_t9spPhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v95NJtBpWQT",
        "outputId": "087a9c09-29f7-4ec1-9faa-c98dda5b985b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ones\n",
        "torch.ones(2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWmDcSmApXtc",
        "outputId": "710f97d4-e756-4aee-b7be-79d42a04c9e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 외의 값을 원한다면 full() 함수에 원하는 형태를 리스트나 튜플로 입력하고, 이어서 어떤 값으로 텐서를 채울지도 입력하면 됩니다."
      ],
      "metadata": {
        "id": "00JmffASL2qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full\n",
        "\n",
        "torch.full((2, 3), 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ffNfXGIpZR8",
        "outputId": "f5d00ded-ddfa-4c54-ed9b-239646a16769"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6, 6, 6],\n",
              "        [6, 6, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quiz.\n",
        " 파이썬 리스트 data_list와 NumPy array data_np가 주어져 있습니다. 이 두 데이터를 PyTorch 텐서로 만들어 주세요.\n",
        "\n",
        "data_list에서 만든 텐서는 tensor_from_list 변수에 저장하고, data_np에서 만든 텐서는 tensor_from_np_array에 저장해야 합니다.\n",
        "\n",
        "```\n",
        "tensor([[ 1,  1],\n",
        "        [-1, -1]])\n",
        "tensor([[3, 4],\n",
        "        [5, 6]])\n",
        "```"
      ],
      "metadata": {
        "id": "k6kf5MF0pjAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "data_list = [\n",
        "    [1, 1],\n",
        "    [-1, -1],\n",
        "]\n",
        "data_np = np.array(\n",
        "    [\n",
        "        [3, 4],\n",
        "        [5, 6]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 여기에 코드를 작성하세요.\n",
        "tensor_from_list = torch.tensor(data_list)\n",
        "tensor_from_np_array = torch.from_numpy(data_np)\n",
        "# tensor_from_np_array = torch.np_\n",
        "# 테스트 코드\n",
        "print(tensor_from_list)\n",
        "print(tensor_from_np_array)"
      ],
      "metadata": {
        "id": "-lmfh4Z7rFTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64de4da-e6bf-46d2-aaba-153fcd62e8be"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  1],\n",
            "        [-1, -1]])\n",
            "tensor([[3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. 텐서의 변환과 연산"
      ],
      "metadata": {
        "id": "ocVwXeJCp87y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 텐서에서 NumPy 배열로 변환하기"
      ],
      "metadata": {
        "id": "uvjUT7SIMHok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch를 사용하다 보면 텐서를 NumPy 배열로 변환해야 할 때가 많습니다.\n",
        "\n",
        "예를 들어, scikit-learn이나 pandas와 함께 사용하거나, matplotlib으로 시각화를 할 때 NumPy 배열이 유용하죠.\n",
        "\n",
        "NumPy 배열은 디버깅할 때도 더 편리합니다.\n",
        "\n",
        "텐서를 NumPy 배열로 변환하는 방법을 살펴보겠습니다."
      ],
      "metadata": {
        "id": "3a8p7NP7MEwg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mkdUwNctivoq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(2, 2)\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "qLo_FvFDi5Mx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df62b86c-8c52-42b5-846a-859b2eec0f98"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy() 메서드를 사용하면 텐서를 NumPy 배열로 변환할 수 있습니다."
      ],
      "metadata": {
        "id": "4Bq0AcwSMK21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = tensor.numpy()\n",
        "np_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFt5SocAjtDT",
        "outputId": "462bffc2-1aea-49af-bae1-b9610b70e05c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "np.array() 함수에 텐서를 입력해도 동일한 결과를 얻을 수 있습니다."
      ],
      "metadata": {
        "id": "pJdZxV7WMNc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array2 = np.array(tensor)\n",
        "np_array2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_yKxCxKj2tm",
        "outputId": "a57870c9-18c7-40e6-da10-655d6ddc5225"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "텐서를 NumPy 배열로 변환할 때 메모리 공유 여부는 방법에 따라 달라집니다.\n",
        "\n",
        "아래 코드를 통해 차이를 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "HAQs55yWMQgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[0, 0] = -1"
      ],
      "metadata": {
        "id": "aA5vaSQskAi4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'numpy() result\\n{np_array}\\n')\n",
        "print(f'np.array() result\\n{np_array2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7AvZW2Ykbg_",
        "outputId": "2465b24a-ef56-446b-ecb3-c854487dd408"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy() result\n",
            "[[-1.  1.]\n",
            " [ 1.  1.]]\n",
            "\n",
            "np.array() result\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `numpy()` 메서드: 텐서와 NumPy 배열이 메모리를 공유함.\n",
        "- `np.array()`: 텐서의 데이터를 복사하여 새로운 NumPy 배열 생성."
      ],
      "metadata": {
        "id": "r3aDGK5mMVK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensor의 연산"
      ],
      "metadata": {
        "id": "kmrLj1rIMni0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch에서는 텐서 간 다양한 연산을 지원합니다.\n",
        "\n",
        "이 중 일부 대표적인 연산을 살펴보겠습니다."
      ],
      "metadata": {
        "id": "87x16Xf7MrE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "b = torch.tensor([[1, 1],\n",
        "                  [2, 2]])"
      ],
      "metadata": {
        "id": "Lt-NZV10kdQH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "같은 크기의 텐서 간 덧셈은 다음과 같이 수행합니다."
      ],
      "metadata": {
        "id": "KnmRg8XEMvJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a + b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxJfWnlck3Dv",
        "outputId": "c9582951-58fd-448c-b6c3-e4576d54e562"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 3],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPq9aqOMk811",
        "outputId": "49d7bdfe-9275-44e5-db9e-d5551988459e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 3],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "요소별 곱셈"
      ],
      "metadata": {
        "id": "do-R-uepMw95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a * b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuIMMudMlH4A",
        "outputId": "43b52603-5fd9-470c-ace7-189a12fa42e3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [6, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multiply(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv6nts1BlOlP",
        "outputId": "95bbbc67-f0e6-48b7-e4cf-7aba9647e2cf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [6, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "행렬 곱셈은 `matmul()` 함수를 사용합니다.\n",
        "\n",
        "곱셈하려는 두 텐서의 차원이 적합해야 합니다."
      ],
      "metadata": {
        "id": "EA9yddYeMz55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(\n",
        "    [\n",
        "        [1, 2],\n",
        "        [3, 4],\n",
        "        [5, 6],\n",
        "        [7, 8],\n",
        "    ]\n",
        ")\n",
        "b = torch.tensor(\n",
        "    [\n",
        "        [1, 0, 0],\n",
        "        [0, 0, 1],\n",
        "        [1, 1, 0],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f'a의 열 개수: {a.shape[1]}')\n",
        "print(f'b의 행 개수: {b.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJfnlrwDlaZm",
        "outputId": "3e781cc6-a704-4c93-882e-339051bf048d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a의 열 개수: 2\n",
            "b의 행 개수: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "x_WPNKnLl9J3",
        "outputId": "9d251b45-3d7f-40ad-d575-5b8ce6e312ff"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (4x2 and 3x3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3511122213.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x2 and 3x3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(\n",
        "    [\n",
        "        [1, 2],\n",
        "        [3, 4],\n",
        "        [5, 6],\n",
        "        [7, 8],\n",
        "    ]\n",
        ")\n",
        "b = torch.tensor(\n",
        "    [\n",
        "        [1, 0, 0],\n",
        "        [0, 0, 1],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f'a의 열 개수: {a.shape[1]}')\n",
        "print(f'b의 행 개수: {b.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1zJLqoemEP1",
        "outputId": "475af76f-0ff1-41a2-f355-5b9104ac928d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a의 열 개수: 2\n",
            "b의 행 개수: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-g7SQu9mQXt",
        "outputId": "9808656a-1542-42c8-8064-72cce40b8c83"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 2],\n",
              "        [3, 0, 4],\n",
              "        [5, 0, 6],\n",
              "        [7, 0, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a @ b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ntpNhRmUHz",
        "outputId": "dca371ed-fa12-42a0-e1df-aafc50b24b98"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 2],\n",
              "        [3, 0, 4],\n",
              "        [5, 0, 6],\n",
              "        [7, 0, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch는 두 텐서의 데이터 타입이 다르면 자동으로 데이터 타입을 일치시킵니다. 이 경우, 정수형 텐서가 실수형으로 변환되어 연산이 이루어집니다.\n"
      ],
      "metadata": {
        "id": "WYM_MfPWNH3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_int = torch.tensor([1, 2], dtype=torch.int32)\n",
        "tensor_float = torch.tensor([3, 4], dtype=torch.float32)\n",
        "\n",
        "add_result = tensor_int + tensor_float\n",
        "mul_result = tensor_int * tensor_float\n",
        "\n",
        "print(add_result)\n",
        "print(mul_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjMY26y8mf7m",
        "outputId": "df5bac77-ccd4-47e7-b9e7-71bacee68ec4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 6.])\n",
            "tensor([3., 8.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(add_result.dtype)\n",
        "print(mul_result.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU42MODlmsZW",
        "outputId": "eb844b71-8aea-4294-d9e0-ddc1b9a9619f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.matmul은 행렬 곱셈을 수행하지만, 두 텐서의 데이터 타입이 다를 경우 에러가 발생합니다.\n",
        "따라서 정수형 텐서를 실수형 텐서로 변환해야 합니다.\n"
      ],
      "metadata": {
        "id": "spvOnm9sNQeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "\n",
        "tensor_int = torch.tensor([1, 2], dtype=torch.int32)\n",
        "tensor_float = torch.tensor(\n",
        "    [\n",
        "        [3, 1],\n",
        "        [1, 4]\n",
        "    ],\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "result2 = tensor_int @ tensor_float\n",
        "result = torch.matmul(tensor_int, tensor_float)\n",
        "print(f\"결과 텐서의 타입: {result.dtype}\") # 결과 텐서의 타입: torch.float32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "XAL3TqeUmuPR",
        "outputId": "d7631dcf-a621-4384-ec17-59d882b6773a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "expected m1 and m2 to have the same dtype, but got: int != float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1045169139.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_int\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtensor_float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"결과 텐서의 타입: {result.dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 결과 텐서의 타입: torch.float32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: int != float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_cast = tensor_int.to(torch.float32)\n",
        "\n",
        "torch.matmul(tensor_cast, tensor_float)"
      ],
      "metadata": {
        "id": "GntvIJiSp0uP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883c1288-23d5-4299-a374-7c980c7584a8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 텐서 인덱싱\n"
      ],
      "metadata": {
        "id": "QIAzmIZpNXbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1차원 텐서의 인덱싱은 넘파이와 동일합니다."
      ],
      "metadata": {
        "id": "wmNEjf6aNcz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([3, 5, 7, 9, 10])"
      ],
      "metadata": {
        "id": "QXci82wlqfqO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbnVYX0zq3gW",
        "outputId": "7d3a8d75-6153-4f20-bc96-d70ab3f1acb1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rMhigAQq8RM",
        "outputId": "8d42be26-0b40-43d9-fdcb-71231670c675"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHPKDUGzq-vU",
        "outputId": "57b91d2c-51f5-45b8-dc86-a6b374f74adb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[::2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDpaR89KrA6l",
        "outputId": "f29732a7-7aac-4045-dd6c-e52b88169686"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  7, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2차원 텐서 인덱싱 및 슬라이싱"
      ],
      "metadata": {
        "id": "b7n5E9zhNhkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d = torch.tensor(\n",
        "    [\n",
        "        [1, 3, 5, 7, 9],\n",
        "        [2, 4, 6, 8, 10],\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "sn8D6S28rGVa"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d[0, :3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_E6TnYgr7MV",
        "outputId": "b9f44271-2d37-4cce-8eee-75ad56bcf3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d[0, 3:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE49pY0fsZn6",
        "outputId": "b8fccef2-3a6b-4d86-cd3b-50a545b8e30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d[:, 1:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHwSrEOeseXD",
        "outputId": "d21d0c26-cae2-4ef7-c935-c46593c4ffed"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3, 5, 7],\n",
              "        [4, 6, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 브로드캐스팅"
      ],
      "metadata": {
        "id": "UwZl5wKdrEXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch에서 텐서 연산을 수행할 때, 두 텐서의 **shape**가 반드시 같을 필요는 없습니다.\n",
        "\n",
        "셰이프가 다른 텐서 간 연산을 자동으로 처리해 주는 기능이 바로 **브로드캐스팅**입니다."
      ],
      "metadata": {
        "id": "uVUzvtlrq7G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a는 2x3 형태의 2차원 텐서, **b**는 크기가 3인 1차원 텐서입니다.\n",
        "\n",
        "이 두 텐서를 더하면 어떻게 될까요?"
      ],
      "metadata": {
        "id": "BC-5NjkeOH9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(\n",
        "    [\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "    ]\n",
        ")\n",
        "b = torch.tensor(\n",
        "    [1, -1, 2],\n",
        ")\n",
        "\n",
        "print(f'a의 shape: {a.shape}')\n",
        "print(f'b의 shape: {b.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acz8bW00dMKf",
        "outputId": "e64141c5-b81d-4cb3-9199-03707bbd8b49"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a의 shape: torch.Size([2, 3])\n",
            "b의 shape: torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a + b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOthS5lsfn2W",
        "outputId": "c752cf8a-2ca3-477c-d7d6-950c0ed2793a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 5],\n",
              "        [5, 4, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서 a의 각 행에 텐서 b가 자동으로 확장되어 덧셈 연산이 이루어졌습니다."
      ],
      "metadata": {
        "id": "KdOU2W__OMlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b_expanded = torch.tensor(\n",
        "    [\n",
        "        [1, -1, 2],\n",
        "        [1, -1, 2],\n",
        "    ]\n",
        ")\n",
        "a + b_expanded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZqsJp1QfzBs",
        "outputId": "e5b4ad07-a846-4850-8c4e-0e6ef40b4fb9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 5],\n",
              "        [5, 4, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 브로드캐스팅 동작원리\n",
        "\n",
        "1. 크기가 1인 차원의 추가 : 차원 수가 적은 텐서는 차원 수가 많은 텐서와 맞추기 위해 **크기가 1인 차원**을 앞에 추가합니다.\n",
        "2. 크기가 1인 차원의 확장 : 확장된 텐서에서 크기가 1인 차원은 상대 텐서에 맞춰 값이 복사됩니다.\n"
      ],
      "metadata": {
        "id": "6DZ4Z3tHOf_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "3ZGVn_GKPK8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 출처 : https://deeplearninguniversity.com/pytorch/pytorch-broadcasting/"
      ],
      "metadata": {
        "id": "v6MOYlyIPOQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(\n",
        "    [\n",
        "        [-1, 1],\n",
        "        [1, 1],\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "wwzdbfdggF8B"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZyMeCl4gXzx",
        "outputId": "6c389cbe-9048-4505-e004-b38dc2751623"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 2],\n",
              "        [2, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a * 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsIs6Cvzgap4",
        "outputId": "cdc71322-efa4-49e1-9342-a72edcd69f06"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2,  2],\n",
              "        [ 2,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(\n",
        "    [\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "    ]\n",
        ")\n",
        "b = torch.tensor(\n",
        "    [1, -1, 2],\n",
        ")\n",
        "\n",
        "print(f'a의 shape: {a.shape}')\n",
        "print(f'b의 shape: {b.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nFr6TVcggAq",
        "outputId": "b683b53d-2bf9-463e-e935-3937faa1082b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a의 shape: torch.Size([2, 3])\n",
            "b의 shape: torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b_expanded = torch.tensor(\n",
        "    [\n",
        "        [1, -1, 2],\n",
        "        [1, -1, 2],\n",
        "    ]\n",
        ")\n",
        "print(b_expanded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnuzwlj3g6PS",
        "outputId": "34848e23-aadd-4523-f47f-0987af921ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 브로드캐스팅이 불가능한 경우\n",
        "\n",
        "브로드캐스팅은 모든 경우에 적용되는 것이 아닙니다.\n",
        "\n",
        "셰이프가 서로 호환되지 않을 경우 연산이 불가능합니다."
      ],
      "metadata": {
        "id": "oGMn9MKXO4d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(\n",
        "    [\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "    ]\n",
        ")\n",
        "b = torch.tensor(\n",
        "    [1, -1],\n",
        ")\n",
        "\n",
        "print(f'a의 shape: {a.shape}')\n",
        "print(f'b의 shape: {b.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNCcGl-ihLT2",
        "outputId": "e60cec15-e4ff-4def-8067-6e224d00bdc7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a의 shape: torch.Size([2, 3])\n",
            "b의 shape: torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a + b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "BkVhSzU7iIiO",
        "outputId": "d11469bf-1d7b-401a-f69f-ab6bfb46dece"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1216668022.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quiz.\n",
        "\n",
        "- 실습 설명   \n",
        "세 개의 텐서 tensor0, tensor1, tensor2가 주어져 있습니다. 다음 단계를 따라 코드를 작성해 주세요.\n",
        "\n",
        "1. tensor0과 tensor1을 더합니다.\n",
        "2. 1번 결과와 tensor2를 행렬곱합니다.\n",
        "3. 2번 결과에서 첫 번째 열에는 2를 더하고, 두 번째 열에서는 2를 뺍니다.\n",
        "4. 3번 결과를 NumPy array로 변환합니다. 이때 변수 이름은 final_np_array로 설정합니다.\n",
        "\n",
        "- 실습 결과   \n",
        "코드 마지막 부분에서 print() 함수로 출력한 결과가 아래처럼 나와야 합니다.\n",
        "\n",
        "```\n",
        "[[ 6 -6]\n",
        " [ 0  0]]\n",
        "```"
      ],
      "metadata": {
        "id": "HmjEQFcqqzWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "tensor0 = torch.tensor(\n",
        "    [\n",
        "        [1, 1],\n",
        "        [-1, -1]\n",
        "    ]\n",
        ")\n",
        "tensor1 = torch.tensor(\n",
        "    [\n",
        "        [1, 1],\n",
        "        [0, 0]\n",
        "    ]\n",
        ")\n",
        "tensor2 = torch.tensor(\n",
        "    [\n",
        "        [1, -1],\n",
        "        [1, -1]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 여기에 코드를 작성하세요.\n",
        "result = tensor0 + tensor1\n",
        "result = result @ tensor2\n",
        "result = result + torch.tensor([\n",
        "    [2,-2]\n",
        "])\n",
        "final_np_array = result.numpy()\n",
        "# 테스트 코드\n",
        "print(final_np_array)"
      ],
      "metadata": {
        "id": "dBKSNkpCqJjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219e8354-63a0-48cd-b350-f16cb3a503fd"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 -6]\n",
            " [ 0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서의 형태 바꾸기"
      ],
      "metadata": {
        "id": "tpsry_IQrLFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch를 사용하다 보면 텐서의 값은 그대로 유지하면서 형태를 바꿔야 하는 경우가 생깁니다.\n",
        "\n",
        "예를 들어, 다차원 텐서를 1차원으로 펼치거나, 차원을 추가하거나, 불필요한 차원을 제거해야 할 때가 있습니다.\n",
        "\n",
        "이 섹션에서는 이러한 작업을 도와주는 메소드들을 살펴보겠습니다."
      ],
      "metadata": {
        "id": "umWpTEdKPmqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### reshape 메소드"
      ],
      "metadata": {
        "id": "YETwR3nqPoLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reshape() 메소드는 텐서의 값을 그대로 두면서 형태를 변경할 수 있습니다."
      ],
      "metadata": {
        "id": "-NivCjQnPuG2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "2z_ybm01s6BW"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 4)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgHMnTMJs9Pc",
        "outputId": "e4ea4938-8177-40b5-df68-4395996b08de"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4475, -0.6904,  0.7236, -0.3824],\n",
              "        [ 0.0948, -0.0581, -0.6474, -0.1236],\n",
              "        [-1.2840,  0.1232, -1.0788, -1.1017]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res0 = x.reshape(2, 6)\n",
        "res0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8QPou60t2a7",
        "outputId": "c451609e-f756-4f60-f474-b3cd6338cc9b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4475, -0.6904,  0.7236, -0.3824,  0.0948, -0.0581],\n",
              "        [-0.6474, -0.1236, -1.2840,  0.1232, -1.0788, -1.1017]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원소 개수가 일치하지 않는 형태로 변환하려 하면 에러가 발생합니다."
      ],
      "metadata": {
        "id": "MuNxqUztPv1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.reshape(2, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "pKl6uIMDt-HT",
        "outputId": "34613928-2ffd-4de6-ab87-8180ae8ff3a3"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[2, 5]' is invalid for input of size 12",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-720558337.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 5]' is invalid for input of size 12"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res3=x.reshape(-1,2,2)\n",
        "res3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWPE8YX6SuGA",
        "outputId": "af05b02a-adeb-4069-fadb-9c8f4eb69d24"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4475, -0.6904],\n",
              "         [ 0.7236, -0.3824]],\n",
              "\n",
              "        [[ 0.0948, -0.0581],\n",
              "         [-0.6474, -0.1236]],\n",
              "\n",
              "        [[-1.2840,  0.1232],\n",
              "         [-1.0788, -1.1017]]])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-1을 사용하면 나머지 차원의 크기를 PyTorch가 자동으로 계산합니다."
      ],
      "metadata": {
        "id": "cgHH8OKmPyaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res1 = x.reshape(-1, 2, 3)\n",
        "res1.size()"
      ],
      "metadata": {
        "id": "j2QV_DuVuOca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33ca38c-4eb3-4195-a09b-5c6c7073bfdc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.reshape(-1) # 1차원으로 펼치기"
      ],
      "metadata": {
        "id": "1GwfPQK3uoKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b58e65-c5d3-4fce-aef5-1fd95d00c842"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.4475, -0.6904,  0.7236, -0.3824,  0.0948, -0.0581, -0.6474, -0.1236,\n",
              "        -1.2840,  0.1232, -1.0788, -1.1017])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `permute()`\n",
        "permute() 메소드는 텐서의 형태를 자유롭게 바꾸는 것이 아니라 차원의 순서만 변경합니다."
      ],
      "metadata": {
        "id": "mC_QvlxfP_TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2, 3, 4)\n",
        "permuted = x.permute(2, 0, 1)  # index다"
      ],
      "metadata": {
        "id": "SzszB3Lnuwe1"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "permuted.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZiLOu0VvSnw",
        "outputId": "d7f3dd80-163d-4250-f593-92ccd31063fe"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `t()` 메소드"
      ],
      "metadata": {
        "id": "hgoFqGJP3x60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#행과 열을 뒤바꾼다\n",
        "\n",
        "x1 = torch.FloatTensor(2,3)\n",
        "x2 = x1.t()\n",
        "print(x1.size())\n",
        "print(x2.size())"
      ],
      "metadata": {
        "id": "6Y__4aEn33vB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2c419e-1de9-4f0b-ff76-078b46374147"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `squeeze()` 메소드"
      ],
      "metadata": {
        "id": "ce5CHf-kQFl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "squeeze() 메소드는 크기가 1인 차원을 제거합니다."
      ],
      "metadata": {
        "id": "aVSDYG2_QJUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 28, 1, 28)"
      ],
      "metadata": {
        "id": "EO7k7RjzvWBO"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result0 = x.squeeze()\n",
        "result0.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm8vmjUzvwSl",
        "outputId": "91209a64-7ede-455a-bedb-ffffde323ced"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정 차원만 제거하려면 차원의 인덱스를 입력합니다."
      ],
      "metadata": {
        "id": "hvfccSmAQMsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = x.squeeze(2)  # index로 제거\n",
        "result1.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov7ClNG6v_Ar",
        "outputId": "ae0e9c9f-a06f-4652-b99e-c2ac9af0fcea"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `unsqueeze()` 메소드"
      ],
      "metadata": {
        "id": "XJQ8pvujQOa2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "unsqueeze() 메소드는 크기가 1인 차원을 추가합니다."
      ],
      "metadata": {
        "id": "xPcEMgViQR4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(28, 28)"
      ],
      "metadata": {
        "id": "Ry7Xny9fwQqr"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result0 = x.unsqueeze(0)\n",
        "result0.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8ONbgy0w5n1",
        "outputId": "354afcf4-58c5-475b-ee35-362493256bc5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = x.unsqueeze(1) # 특정 위치에 차원을 추가할 수도 있습니다.\n",
        "result1.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75wXGoBHxE5j",
        "outputId": "d017bccc-dd7d-4dfa-d92f-ae9de684355a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 1, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (심화) view() 메소드와 contiguous 개념"
      ],
      "metadata": {
        "id": "qV66WpG7ruGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "view() 메소드도 reshape() 메소드와 마찬가지로 전체 원소 개수를 유지하면서 텐서의 형태를 바꿀 때 사용합니다. 즉, 아래처럼 3x4 텐서가 있다고 하면, 원소 개수가 12개인 형태로 자유롭게 바꿀 수 있습니다."
      ],
      "metadata": {
        "id": "4CoqCYv-rxl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 4)\n",
        "result = x.view(2, 6)  # 2 x 6 = 12\n",
        "\n",
        "print(result.size())  # torch.Size([2, 6])"
      ],
      "metadata": {
        "id": "hbyZ1g1nrZmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b55502-ee47-4724-8a0d-05729ba32bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "view() 메소드에서도 -1을 넣어 준 차원의 크기는 전체 원소 개수와 나머지 차원의 크기를 고려해 자동으로 지정됩니다."
      ],
      "metadata": {
        "id": "fLXJfBqpQe1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = x.view(-1, 2, 3)  # (?) x 2 x 3 = 12\n",
        "\n",
        "print(result.size())  # torch.Size([2, 2, 3])"
      ],
      "metadata": {
        "id": "50CEgeapr1vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85a75dc-bd1b-4d2d-e01a-86338c1e7f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = x.view(-1)\n",
        "\n",
        "print(result.size())  # torch.Size([12])"
      ],
      "metadata": {
        "id": "Zuf0TIBZr28s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1cecf3-ad19-461f-a14a-3c433fa07b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "view() 메소드로 나온 텐서는 원본 텐서와 메모리를 공유합니다. 아래 코드처럼 모든 값이 1인 텐서 x가 있고, view() 메소드로 형태를 바꾼 텐서 x_view가 있다고 해 볼게요."
      ],
      "metadata": {
        "id": "YpF4TtiRr6AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 3)\n",
        "x_view = x.view(-1)\n",
        "\n",
        "x[0, 0] = 0\n",
        "print(x_view)  # tensor([0., 1., 1., 1., 1., 1.])"
      ],
      "metadata": {
        "id": "MI4WDTW3r37w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36493fb-11e7-4a52-d18e-8ab5c4d5ac2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "두 텐서가 메모리를 공유하기 때문에, 원본 텐서인 x에서 값을 바꾸면 x_view 역시 영향을 받게 됩니다."
      ],
      "metadata": {
        "id": "h6Y4MLHOr9_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contiguous란?"
      ],
      "metadata": {
        "id": "NskSNI7xQnMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`view()` 메소드처럼 메모리를 공유하면서 텐서 형태를 바꾸려면, 텐서 값이 연속된 메모리 공간에 존재해야 합니다. PyTorch에서는 연속된 메모리를 갖는 텐서를 contiguous하다고 표현해요. 즉, contiguous한 텐서에서만 `view()` 메소드를 사용할 수 있는 겁니다.\n",
        "\n",
        "어떤 텐서가 contiguous한지 알아보려면 `is_contiguous()` 메소드를 확인해 보면 됩니다. `True`면 contiguous한 텐서인 거고, `False`면 contiguous하지 않은 텐서인 거죠."
      ],
      "metadata": {
        "id": "gzIrh_RNsDBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.is_contiguous()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBF9Xs7tr-p3",
        "outputId": "09051aff-7bec-48ef-f291-d6c5143ca9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제로 PyTorch를 사용하다 보면 contiguous하지 않은 텐서가 만들어질 수 있습니다. 대표적으로 앞서 배운 permute() 메소드를 사용할 때가 있고요. 텐서를 슬라이싱하기만 해도 contiguous하지 않은 텐서가 나옵니다."
      ],
      "metadata": {
        "id": "7LsyofBVsGPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(3, 16, 28)\n",
        "x_permuted = x.permute(2, 1, 0)\n",
        "x_sliced = x[:, :, :10]\n",
        "\n",
        "print(x_permuted.is_contiguous())  # False\n",
        "print(x_sliced.is_contiguous())  # False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBFSsOeSsEWY",
        "outputId": "0d1757b6-535a-4b64-8c1a-b16a9b084fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contiguous하지 않은 텐서에서 view() 메소드를 사용하면 오류가 납니다. 그래서 아래처럼 contiguous() 메소드를 호출해서 먼저 contiguous한 텐서를 만들어 줘야 해요."
      ],
      "metadata": {
        "id": "uBHgkgVisI0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x가 contiguous하지 않을 때\n",
        "x_cont = x.contiguous()\n",
        "x_cont.view(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlUQ1Hr1sH7k",
        "outputId": "3152acc9-e386-43ec-eaaa-540e0fe7da1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.,  ..., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "한편 `reshape()` 메소드는 `view()` 메소드와 달리, 텐서가 contiguous하지 않아도 정상적으로 코드가 실행됩니다. 만약 contiguous한 텐서에서 `reshape()` 메소드를 사용하면 `view()` 메소드처럼 원본 텐서와 메모리를 공유하는 텐서가 나오고요. Contiguous하지 않은 텐서에서 사용하면, 원본 텐서에서 데이터만 복사되어 새로운 메모리를 갖는 텐서가 나옵니다.\n",
        "\n",
        "앞서 배웠듯이 `view()` 메소드는 텐서가 contiguous하지 않으면 오류가 납니다. 텐서가 반드시 contiguous하다고 보장할 수 있다면 `view()` 메소드를 써도 좋지만, 안정적인 실행을 위해서는 되도록 `reshape()` 메소드를 쓰는 게 낫습니다. 하지만 `reshape()` 메소드를 쓸 때도 상황에 따라 원본 텐서와 reshape된 텐서가 메모리를 공유할 수도 있고 그러지 않을 수도 있어요. 이를 잘 고려하여 코드를 작성해야겠죠."
      ],
      "metadata": {
        "id": "d_uano60sMfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `transpose()` 메소드"
      ],
      "metadata": {
        "id": "y6Saazbv4Ke9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.transpose()를 이용하여 특정 dimension을 변경할 수 있습니다."
      ],
      "metadata": {
        "id": "2qXg_x5r4S64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.FloatTensor(10,3,4,5)\n",
        "print(x1.size())\n",
        "print(torch.transpose(x1,1,2).size())\n",
        "print(torch.transpose(x1,2,3).size())"
      ],
      "metadata": {
        "id": "7RyyN5vF4VT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여러 텐서 합치기"
      ],
      "metadata": {
        "id": "1RMgf2masig3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch를 사용하다 보면 여러 텐서를 하나로 합쳐야 하는 경우가 자주 있습니다.\n",
        "\n",
        "이번 섹션에서는 이를 위한 두 가지 주요 함수, `cat()`과 `stack()`을 살펴보겠습니다."
      ],
      "metadata": {
        "id": "onUofL31SYTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `cat() 함수`"
      ],
      "metadata": {
        "id": "JXrPajt4SY0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`cat()` 함수는 여러 텐서를 특정 차원에 따라 **이어 붙이는** 함수입니다.\n",
        "\n",
        "이 과정을 **컨캐터네이트(concatenate)**라고도 부릅니다."
      ],
      "metadata": {
        "id": "1TJ7p8mwSdhj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa-u86HWJ3x3"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "y = torch.ones(2, 3)"
      ],
      "metadata": {
        "id": "LMAkxcWzJ70I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate\n",
        "cat0 = torch.cat([x, y], dim=0)\n",
        "cat1 = torch.cat([x, y], dim=1)"
      ],
      "metadata": {
        "id": "Xs5VxZquL0oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **dim=0**: 텐서를 **행 방향**으로 붙입니다.\n",
        "- **dim=1**: 텐서를 **열 방향**으로 붙입니다."
      ],
      "metadata": {
        "id": "bpYMuhdCSf1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cat0)\n",
        "print(cat0.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIFN9HnAMS4f",
        "outputId": "9e110968-76fd-460e-811f-d8c1e6856965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cat1)\n",
        "print(cat1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LONAYuB8MW1U",
        "outputId": "2336cb1d-d278-4c87-ab13-f30d856179d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1., 1.]])\n",
            "torch.Size([2, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 조건: 이어 붙일 텐서의 크기 제한\n",
        "\n",
        "기준 차원을 제외한 나머지 차원의 크기가 같아야 합니다."
      ],
      "metadata": {
        "id": "QGHa0Sa6SkFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "y = torch.ones(2, 4)"
      ],
      "metadata": {
        "id": "AQLKzuiWMkpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat1 = torch.cat((x, y), dim=1)\n",
        "\n",
        "print(cat1)\n",
        "print(cat1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0A6rNxNA65",
        "outputId": "eb46ff58-bb3a-426c-cd37-21e8b1604bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1., 1., 1.]])\n",
            "torch.Size([2, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat0 = torch.cat((x, y), dim=0) # dim=0에서는 나머지 차원의 크기가 다르기 때문에 에러가 발생합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "zaPrAxktNP_M",
        "outputId": "e218013f-0fbe-42dc-96b1-9835faa74c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 0. Expected size 3 but got size 4 for tensor number 1 in the list.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-5c763d12aa1e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dim=0에서는 나머지 차원의 크기가 다르기 때문에 에러가 발생합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 3 but got size 4 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "y = torch.ones(2, 3)"
      ],
      "metadata": {
        "id": "1mu7yKbeNnHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `stack()` 함수"
      ],
      "metadata": {
        "id": "G_GVNVt_SxJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "`stack()` 함수는 여러 텐서를 특정 차원에 따라 **쌓는** 함수입니다.\n",
        "\n",
        "`cat()` 함수와 달리, 결과 텐서에는 **새로운 차원**이 추가됩니다."
      ],
      "metadata": {
        "id": "u6gY4t4WSz1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stack_result = torch.stack([x, y], dim=0)\n",
        "cat_result = torch.cat([x, y], dim=0)"
      ],
      "metadata": {
        "id": "i9LmZhTFOBMQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "d2122009-bda9-4c44-80c3-e2662ff87acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [2, 3] at entry 0 and [2, 4] at entry 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-f412fcb4bc0b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstack_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 3] at entry 0 and [2, 4] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stack_result.size())\n",
        "print(stack_result, '\\n')\n",
        "\n",
        "print(cat_result.size())\n",
        "print(cat_result)"
      ],
      "metadata": {
        "id": "KBKXPKRwOWAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- dim=0: 새로운 0번 차원이 추가됩니다."
      ],
      "metadata": {
        "id": "tXAs2ASwS9X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stack_result_dim2 = torch.stack([x, y], dim=2) # dim=2: 새로운 2번 차원이 추가됩니다.\n",
        "\n",
        "print(stack_result_dim2.size())\n",
        "print(stack_result_dim2)"
      ],
      "metadata": {
        "id": "RhW7HnzkOX4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  조건: 합칠 텐서의 크기 제한\n",
        "\n",
        "`stack()` 함수로 합칠 텐서는 반드시 크기가 같아야 합니다.\n",
        "\n",
        "**dim** 값에 관계없이 동일한 형태의 텐서만 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "jBXLRjLmTC7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "y = torch.ones(2, 4)\n",
        "\n",
        "torch.stack([x, y], dim=1)"
      ],
      "metadata": {
        "id": "wPyIy1HGOpIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `cat()` vs `stack()` 요약\n",
        "\n",
        "| 함수 | 차원 추가 여부 | 제한 사항 |\n",
        "| --- | --- | --- |\n",
        "| `cat` | 없음 | 기준 차원을 제외한 크기가 같아야 함 |\n",
        "| `stack` | 있음 | 모든 차원의 크기가 같아야 함 |"
      ],
      "metadata": {
        "id": "0vurW16UTGhD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 한 텐서를 여러 텐서로 나누기"
      ],
      "metadata": {
        "id": "8V0QfQRp_YcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### split()"
      ],
      "metadata": {
        "id": "TkWN7rYXTLLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(\n",
        "    [\n",
        "        [1, 2, 3, 4, 5],\n",
        "        [6, 7, 8, 9, 10],\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Lt7CFsnOsniq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split() 메소드를 사용하면 텐서를 원하는 크기대로 나눌 수 있습니다. 메소드에 나누고 싶은 크기와 기준 차원을 입력해 주면 돼요. 나누어진 텐서들은 튜플로 묶여서 리턴됩니다. 아래 코드는 x를 0번 차원 기준으로 크기가 1이 되도록 나눕니다."
      ],
      "metadata": {
        "id": "gh0jU1OnBVw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.split(1, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwK0cjMKBT-I",
        "outputId": "75ff03b1-a0bc-4182-f8a5-4738de53eb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3, 4, 5]]), tensor([[ 6,  7,  8,  9, 10]]))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 차원 기준으로 크기가 2인 텐서가 되도록 나누면 어떻게 될까요?      \n",
        "- x가 2x5 텐서이기 때문에 1번 차원 기준으로 5가 2로 나누어 떨어지지 않습니다.\n",
        "- 이럴 때는 일단 지정한 크기대로 최대한 텐서를 만들어 본 뒤 마지막 텐서는 더 작은 크기로 만들게 됩니다. 따라서 2x2 텐서 두 개가 나오고 나머지 크기만큼 2x1 텐서 하나가 나오죠.\n",
        "- 즉, 상황에 따라서 마지막 텐서는 크기가 지정한 것보다 더 작을 수도 있어요."
      ],
      "metadata": {
        "id": "1ViC57CoBcL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.split(2, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtC6MdpoBc1h",
        "outputId": "410354a3-3aad-4b24-c552-ab2a7a7b7f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2],\n",
              "         [6, 7]]),\n",
              " tensor([[3, 4],\n",
              "         [8, 9]]),\n",
              " tensor([[ 5],\n",
              "         [10]]))"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### chunk() 메소드"
      ],
      "metadata": {
        "id": "TdzBYoi2TY96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`chunk()` 메소드로도 하나의 텐서를 여러 텐서로 나눌 수 있습니다. `split()`이 크기를 지정해서 텐서를 나눈다면, `chunk()`는 개수를 지정해서 텐서를 나누게 돼요. 메소드에 나누고 싶은 텐서의 개수와 기준 차원을 입력해 주면 됩니다. 나누어진 텐서들은 튜플로 묶여서 리턴됩니다.\n",
        "\n",
        "위와 동일한 `x`가 있다고 했을 때, 아래 코드는 `x`를 0번 차원 기준으로 텐서 2개가 되도록 나눕니다. `x`가 2x5 텐서이기 때문에, 0번 차원으로는 텐서 두 개가 딱 떨어지게 나뉠 수 있어요."
      ],
      "metadata": {
        "id": "8XjjAITHBvRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rEBeNHaUdzG",
        "outputId": "d1ad63f1-c32d-440d-98f9-0110b9c50769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.chunk(2, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRgZcQOjBkUX",
        "outputId": "04cfb3f9-5542-4b94-a852-1237a1882091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3, 4, 5]]), tensor([[ 6,  7,  8,  9, 10]]))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 1번 차원 기준으로 텐서를 셋으로 나눠 볼게요. x가 2x5 텐서니까 1번 차원 기준으로 텐서를 삼등분할 수는 없습니다. 이런 경우에는 일단 같은 크기로 텐서를 최대한 나누고, 마지막 텐서만 더 작은 크기를 갖게 됩니다. 결과를 보면 2x2 텐서 두 개에 2x1 텐서가 하나 나오죠."
      ],
      "metadata": {
        "id": "nacMmQnDBzoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.chunk(3, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs8EhcoDBx_E",
        "outputId": "d1678ff5-3982-4af3-bcf9-5c2514d4d62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2],\n",
              "         [6, 7]]),\n",
              " tensor([[3, 4],\n",
              "         [8, 9]]),\n",
              " tensor([[ 5],\n",
              "         [10]]))"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 1번 차원 기준으로 텐서를 넷으로 나누면 어떻게 될까요? x가 2x5 텐서인데 1번 차원 기준으로 크기가 2인 텐서를 세 개만 만들어도 6이 되니까 5를 넘어 버립니다. 결국 이 경우에는 2x2 텐서가 두 개까지밖에 나오지 못하며, 여기에 2x1 텐서 하나가 함께 나오게 돼요. 텐서를 넷으로 나누려고 했는데 세 개만 나온 거죠. 이처럼 상황에 따라 지정한 개수보다 더 적은 수로 텐서가 나뉠 수도 있습니다."
      ],
      "metadata": {
        "id": "eR4SueKaB6MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.chunk(4, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA95ehkXB1Nz",
        "outputId": "96af75bd-b37c-4baf-e561-498a2f41fd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2],\n",
              "         [6, 7]]),\n",
              " tensor([[3, 4],\n",
              "         [8, 9]]),\n",
              " tensor([[ 5],\n",
              "         [10]]))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.chunk(4, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRRvsbMhB7eV",
        "outputId": "bc0cf69f-fe9c-4e38-fe2e-82b526eaf1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2],\n",
              "         [6, 7]]),\n",
              " tensor([[3, 4],\n",
              "         [8, 9]]),\n",
              " tensor([[ 5],\n",
              "         [10]]))"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "즉,\n",
        "- 주어진 차원(`dim`)의 텐서 크기가 지정된 `chunks`로 나누어 떨어지는 경우, 반환된 모든 조각(chunk)은 동일한 크기를 가집니다.\n",
        "- 그러나 주어진 차원의 텐서 크기가 `chunks`로 나누어 떨어지지 않는 경우, 반환된 조각들 중 마지막 조각만 다른 크기를 가질 수 있습니다.\n",
        "- 이러한 분할이 불가능한 경우, 반환되는 조각의 수는 지정된 `chunks`보다 적을 수 있습니다."
      ],
      "metadata": {
        "id": "6tsKHxfUVJGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU"
      ],
      "metadata": {
        "id": "z36GMinzCf8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "yzi3cieJC36B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥 러닝 연산이라고 하면 굉장히 복잡할 것 같지만, 사실 앞서 살펴본 행렬 곱셈, 요소별 덧셈과 같은 행렬 연산이 대부분이에요. 딥 러닝 모델은 이런 기본적인 행렬 연산을 대규모로 여러 번 반복하여 복잡한 패턴을 학습하고 예측하게 됩니다.\n",
        "\n",
        "GPU는 이런 대규모 행렬 연산을 빠르고 효율적으로 처리할 수 있는 장치예요. 그래서 딥 러닝의 발전을 이야기할 때면 GPU가 빠지지 않고 등장합니다."
      ],
      "metadata": {
        "id": "drgx_dvVCk1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch에서는 연산 장치를 명시적으로 설정하지 않으면 텐서를 기본적으로 CPU에 만들어요."
      ],
      "metadata": {
        "id": "P5uGQIocCmkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab에서 GPU 환경을 활성화한 상태로 텐서를 만든 뒤, 이 텐서가 어떤 장치에서 만들어졌는지 확인해 봅시다. 텐서 객체의 device 속성을 확인하면 돼요. GPU를 사용할 수 있는 환경임에도 텐서는 CPU에 만들어집니다."
      ],
      "metadata": {
        "id": "g7TylVqxCoRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2])\n",
        "print(tensor.device)  # cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bOLb3FVCfid",
        "outputId": "daf0892f-32c2-4fb9-ef1e-548a1948ccb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU를 사용할 수 있는 환경이라면 CPU에 있는 텐서를 GPU로 옮길 수 있습니다. CPU에 있는 텐서를 GPU에 옮기기 전에, 우선 GPU를 사용할 수 있는 환경인지 먼저 체크해 주는 게 좋은데요.\n",
        "\n",
        "아래처럼 코드를 작성하고 실행해 보세요. 결과가 True면 GPU를 사용할 수 있고, False면 GPU를 사용할 수 없습니다."
      ],
      "metadata": {
        "id": "3MDS0Tf7CrqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AvZVoZICpmX",
        "outputId": "3b432d25-3042-404d-aaa4-4a754045a0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CPU에 있는 텐서를 GPU로 옮길 때는 텐서의 `to()` 메소드를 이용하면 됩니다. 텐서의 데이터 타입을 바꿀 때 사용했던 메소드와 같은 메소드예요. `device` 속성을 확인했을 때 cuda라는 표시와 함께 숫자가 나오면 텐서가 GPU에 있다는 뜻입니다. 여기서 숫자 0은 GPU의 인덱스를 나타냅니다."
      ],
      "metadata": {
        "id": "hslp32URCvH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = tensor.to('cuda')\n",
        "\n",
        "print(tensor_gpu.device)  # cuda:0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz33UTjwCtIE",
        "outputId": "512a01ed-b612-4750-e726-161f37a65a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to() 메소드 대신 cuda() 메소드를 사용해도 됩니다. 다만 CPU에서 GPU로 텐서를 옮길 때에는 to() 메소드가 더 많이 사용되는 편입니다."
      ],
      "metadata": {
        "id": "35gQrbo5CyOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = tensor.cuda()\n",
        "\n",
        "print(tensor_gpu.device)  # cuda:0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4VhdvDQCwXB",
        "outputId": "0555fe03-697b-4e37-d1f7-a221c04f7fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러 대의 GPU를 사용할 수 있는 환경이라면 인덱스가 0, 1, 2, 3, … 이렇게 커지면서 서로 다른 GPU를 가리킬 수 있습니다. 예를 들어 GPU가 2대라면 아래처럼 0번 GPU와 1번 GPU에 각각 텐서를 옮길 수 있어요."
      ],
      "metadata": {
        "id": "PigIckYMC8Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_gpu0 = tensor.to('cuda:0')\n",
        "tensor_gpu1 = tensor.to('cuda:1')"
      ],
      "metadata": {
        "id": "AXVwD6_1C0Ix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3a8ec734-993e-4e8d-9481-1418df057e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-4bf56822b57f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor_gpu0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_gpu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 GPU를 사용할 수 없는 환경에서 텐서를 GPU로 옮기려고 하면 다음과 같은 오류가 발생합니다."
      ],
      "metadata": {
        "id": "IiNKgRJcC_SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
      ],
      "metadata": {
        "id": "7koi0ezrC-KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPU에 있는 텐서를 CPU로 옮기기\n",
        "\n",
        "그런데 PyTorch를 사용하다 보면 GPU에 있는 텐서를 CPU로 옮겨야 할 때도 많습니다. 예를 들어 텐서를 NumPy array로 바꿔야 할 때, GPU 메모리를 효율적으로 관리해야 할 때 등이 그렇죠.\n",
        "\n",
        "GPU에 있는 텐서를 CPU로 옮길 때도 `to()` 메소드를 사용하면 됩니다."
      ],
      "metadata": {
        "id": "IUf9XSFyDEsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_cpu = tensor_gpu.to('cpu')\n",
        "print(tensor_cpu.device)  # cpu"
      ],
      "metadata": {
        "id": "K0VjtBuiDDFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68748927-88f0-42d4-f4dc-de43512c76ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 또는 cpu() 메소드를 사용해도 같은 결과가 나옵니다. 참고로 GPU 텐서를 CPU로 옮길 때에는 to() 메소드보다 cpu() 메소드가 더 많이 쓰이는 편이에요."
      ],
      "metadata": {
        "id": "4Fka3imFDHEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_cpu = tensor_gpu.cpu()\n",
        "print(tensor_cpu.device)  # cpu"
      ],
      "metadata": {
        "id": "1s907AiWDI5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c781142d-a003-4be4-c76b-20e71d2a09d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `torch.device`로 장치 관리하기\n",
        "\n",
        "PyTorch에서 제공하는 `device` 객체를 활용하면 장치를 보다 편하게 관리할 수 있습니다. 이런 식으로 `torch.device()`에 원하는 장치를 입력해 `device` 객체를 만들 수 있어요."
      ],
      "metadata": {
        "id": "qc-u1BICDOQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda')\n",
        "device_gpu1 = torch.device('cuda:1')  # GPU가 2대 이상일 시"
      ],
      "metadata": {
        "id": "KSSTb0AIDN_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래처럼 torch.cuda.is_available()에 따라 장치가 결정되도록 device 객체를 만드는 경우가 많습니다. 이 코드는 앞으로도 자주 나오니까 꼭 기억해 주세요."
      ],
      "metadata": {
        "id": "ULbE-KEYDSiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_adaptive = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "BaUbwfOpDQ1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "한번 device 객체를 만들어 놓으면 이후에는 문자열이 아니라 객체를 사용해 텐서의 장치를 설정하면 됩니다. to() 메소드를 쓸 때에는 메소드 입력으로 device 객체를 넣어 주고, 텐서를 만들면서 device 파라미터를 쓸 때는 파라미터에 device 객체를 입력해 주세요."
      ],
      "metadata": {
        "id": "JxzbKYT2DZAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3]).to(device_adaptive)\n",
        "tensor = torch.tensor([1, 2, 3], device=device_adaptive)"
      ],
      "metadata": {
        "id": "7pHc3Md9DXZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 텐서 연산 시 주의할 점\n",
        "\n",
        "텐서와 텐서가 어떤 연산을 할 때 두 텐서의 연산 장치는 동일해야 합니다. 그러니까 CPU에 있는 텐서끼리만 연산이 가능하고, 동일한 GPU에 있는 텐서끼리만 연산이 가능해요.\n",
        "\n",
        "아래 코드는 CPU 텐서와 GPU 텐서를 더해 주는 코드입니다."
      ],
      "metadata": {
        "id": "jhrmrNZRDbgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_cpu = torch.ones(1, 4)\n",
        "tensor_gpu = torch.zeros(1, 4, device=torch.device('cuda'))\n",
        "\n",
        "tensor_cpu + tensor_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "7QOVKSwYDaNg",
        "outputId": "241338b0-8f9d-4c03-e571-106403ddd27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-a3d00eae4092>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtensor_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtensor_cpu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor_gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실행하면 아래와 같이 텐서의 연산 장치가 다르다는 오류가 발생합니다."
      ],
      "metadata": {
        "id": "rRYyALzoDe5T"
      }
    }
  ]
}