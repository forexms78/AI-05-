{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnSni/l6nLn82cKbHoFO/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forexms78/AI-05-/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5aut9XlgDnk"
      },
      "source": [
        "# Seq2Seq 실습 1: 영어-한국어 번역\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncKkATlYgDnl"
      },
      "source": [
        "### 1. 환경 설정 및 라이브러리 설치\n",
        "\n",
        "* `torch`: 딥러닝 프레임워크\n",
        "* `torchtext`: 텍스트 처리를 위한 라이브러리\n",
        "* `spacy`: 영어 토큰화\n",
        "* `konlpy`: 한국어 토큰화 (Okt 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hnVBaX64gDnl",
        "outputId": "c5f78183-6033-454e-c4aa-f0daad7411e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision==0.18.0\n",
            "  Downloading torchvision-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchaudio==2.3.0\n",
            "  Downloading torchaudio-2.3.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchtext==0.18.0\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0) (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.0-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.3.0-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchtext, torchaudio\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchtext-0.18.0 torchvision-0.18.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (2.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (495 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.9/495.9 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.6.0 konlpy-0.6.0\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ca-certificates-java fonts-dejavu-core fonts-dejavu-extra java-common\n",
            "  libatk-wrapper-java libatk-wrapper-java-jni libgail-common libgail18\n",
            "  libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libpcsclite1 librsvg2-common\n",
            "  libxt-dev libxtst6 libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  default-jre gvfs pcscd libxt-doc openjdk-8-demo openjdk-8-source visualvm\n",
            "  libnss-mdns fonts-nanum fonts-ipafont-gothic fonts-ipafont-mincho\n",
            "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  ca-certificates-java fonts-dejavu-core fonts-dejavu-extra java-common\n",
            "  libatk-wrapper-java libatk-wrapper-java-jni libgail-common libgail18\n",
            "  libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libpcsclite1 librsvg2-common\n",
            "  libxt-dev libxtst6 libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 21 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 50.0 MB of archives.\n",
            "After this operation, 169 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 java-common all 0.72build2 [6,782 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcsclite1 amd64 1.9.5-3ubuntu1 [19.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [30.8 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ca-certificates-java all 20190909ubuntu1.2 [12.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre amd64 8u462-ga~us1-0ubuntu2~22.04.2 [75.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [8,849 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk amd64 8u462-ga~us1-0ubuntu2~22.04.2 [4,105 kB]\n",
            "Fetched 50.0 MB in 2s (33.1 MB/s)\n",
            "Selecting previously unselected package java-common.\n",
            "(Reading database ... 125082 files and directories currently installed.)\n",
            "Preparing to unpack .../00-java-common_0.72build2_all.deb ...\n",
            "Unpacking java-common (0.72build2) ...\n",
            "Selecting previously unselected package libpcsclite1:amd64.\n",
            "Preparing to unpack .../01-libpcsclite1_1.9.5-3ubuntu1_amd64.deb ...\n",
            "Unpacking libpcsclite1:amd64 (1.9.5-3ubuntu1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../02-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../03-openjdk-8-jre-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package ca-certificates-java.\n",
            "Preparing to unpack .../04-ca-certificates-java_20190909ubuntu1.2_all.deb ...\n",
            "Unpacking ca-certificates-java (20190909ubuntu1.2) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../07-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../08-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../09-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../10-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../11-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../12-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../13-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../14-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../15-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../16-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../17-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../18-openjdk-8-jre_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../19-openjdk-8-jdk-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../20-openjdk-8-jdk_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Setting up java-common (0.72build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up libpcsclite1:amd64 (1.9.5-3ubuntu1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up ca-certificates-java (20190909ubuntu1.2) ...\n",
            "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
            "Adding debian:GlobalSign_Root_CA.pem\n",
            "Adding debian:Certigna.pem\n",
            "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
            "Adding debian:Certainly_Root_E1.pem\n",
            "Adding debian:Amazon_Root_CA_3.pem\n",
            "Adding debian:certSIGN_Root_CA_G2.pem\n",
            "Adding debian:vTrus_ECC_Root_CA.pem\n",
            "Adding debian:Amazon_Root_CA_2.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM_SERVIDORES_SEGUROS.pem\n",
            "Adding debian:AffirmTrust_Premium.pem\n",
            "Adding debian:DigiCert_TLS_RSA4096_Root_G5.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
            "Adding debian:emSign_Root_CA_-_G1.pem\n",
            "Adding debian:Secure_Global_CA.pem\n",
            "Adding debian:Amazon_Root_CA_1.pem\n",
            "Adding debian:certSIGN_ROOT_CA.pem\n",
            "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
            "Adding debian:Certigna_Root_CA.pem\n",
            "Adding debian:GTS_Root_R4.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
            "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
            "Adding debian:ISRG_Root_X2.pem\n",
            "Adding debian:GTS_Root_R1.pem\n",
            "Adding debian:Starfield_Class_2_CA.pem\n",
            "Adding debian:Baltimore_CyberTrust_Root.pem\n",
            "Adding debian:GTS_Root_R3.pem\n",
            "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:Comodo_AAA_Services_root.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:Actalis_Authentication_Root_CA.pem\n",
            "Adding debian:CA_Disig_Root_R2.pem\n",
            "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
            "Adding debian:XRamp_Global_CA_Root.pem\n",
            "Adding debian:Certum_Trusted_Root_CA.pem\n",
            "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
            "Adding debian:Security_Communication_ECC_RootCA1.pem\n",
            "Adding debian:Certum_Trusted_Network_CA.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
            "Adding debian:ISRG_Root_X1.pem\n",
            "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
            "Adding debian:TWCA_Root_Certification_Authority.pem\n",
            "Adding debian:HARICA_TLS_RSA_Root_CA_2021.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
            "Adding debian:HARICA_TLS_ECC_Root_CA_2021.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
            "Adding debian:GlobalSign_Root_R46.pem\n",
            "Adding debian:emSign_Root_CA_-_C1.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
            "Adding debian:HiPKI_Root_CA_-_G1.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
            "Adding debian:DigiCert_TLS_ECC_P384_Root_G5.pem\n",
            "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
            "Adding debian:Go_Daddy_Class_2_CA.pem\n",
            "Adding debian:SecureTrust_CA.pem\n",
            "Adding debian:TWCA_Global_Root_CA.pem\n",
            "Adding debian:e-Szigno_Root_CA_2017.pem\n",
            "Adding debian:Atos_TrustedRoot_2011.pem\n",
            "Adding debian:Security_Communication_Root_CA.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
            "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
            "Adding debian:UCA_Global_G2_Root.pem\n",
            "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:SZAFIR_ROOT_CA2.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
            "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
            "Adding debian:GLOBALTRUST_2020.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority.pem\n",
            "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
            "Adding debian:D-TRUST_EV_Root_CA_1_2020.pem\n",
            "Adding debian:AffirmTrust_Commercial.pem\n",
            "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
            "Adding debian:UCA_Extended_Validation_Root.pem\n",
            "Adding debian:AffirmTrust_Networking.pem\n",
            "Adding debian:ACCVRAIZ1.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
            "Adding debian:Certainly_Root_R1.pem\n",
            "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
            "Adding debian:Buypass_Class_2_Root_CA.pem\n",
            "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
            "Adding debian:vTrus_Root_CA.pem\n",
            "Adding debian:AffirmTrust_Premium_ECC.pem\n",
            "Adding debian:DigiCert_Global_Root_CA.pem\n",
            "Adding debian:Security_Communication_RootCA3.pem\n",
            "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
            "Adding debian:Security_Communication_RootCA2.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
            "Adding debian:COMODO_Certification_Authority.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
            "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:Telia_Root_CA_v2.pem\n",
            "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
            "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
            "Adding debian:Buypass_Class_3_Root_CA.pem\n",
            "Adding debian:GTS_Root_R2.pem\n",
            "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
            "Adding debian:QuoVadis_Root_CA_2.pem\n",
            "Adding debian:QuoVadis_Root_CA_3.pem\n",
            "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
            "Adding debian:Izenpe.com.pem\n",
            "Adding debian:ANF_Secure_Server_Root_CA.pem\n",
            "Adding debian:TunTrust_Root_CA.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
            "Adding debian:Certum_EC-384_CA.pem\n",
            "Adding debian:CFCA_EV_ROOT.pem\n",
            "Adding debian:DigiCert_Global_Root_G3.pem\n",
            "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
            "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:SecureSign_RootCA11.pem\n",
            "Adding debian:Amazon_Root_CA_4.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
            "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
            "Adding debian:ePKI_Root_Certification_Authority.pem\n",
            "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
            "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:DigiCert_Global_Root_G2.pem\n",
            "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
            "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
            "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
            "Adding debian:GlobalSign_Root_E46.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
            "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
            "Adding debian:D-TRUST_BR_Root_CA_1_2020.pem\n",
            "Adding debian:Atos_TrustedRoot_Root_CA_RSA_TLS_2021.pem\n",
            "Adding debian:CommScope_Public_Trust_RSA_Root-02.pem\n",
            "Adding debian:BJCA_Global_Root_CA2.pem\n",
            "Adding debian:Atos_TrustedRoot_Root_CA_ECC_TLS_2021.pem\n",
            "Adding debian:CommScope_Public_Trust_RSA_Root-01.pem\n",
            "Adding debian:TrustAsia_Global_Root_CA_G3.pem\n",
            "Adding debian:BJCA_Global_Root_CA1.pem\n",
            "Adding debian:CommScope_Public_Trust_ECC_Root-02.pem\n",
            "Adding debian:CommScope_Public_Trust_ECC_Root-01.pem\n",
            "Adding debian:SSL.com_TLS_ECC_Root_CA_2022.pem\n",
            "Adding debian:TrustAsia_Global_Root_CA_G4.pem\n",
            "Adding debian:SSL.com_TLS_RSA_Root_CA_2022.pem\n",
            "Adding debian:Sectigo_Public_Server_Authentication_Root_E46.pem\n",
            "Adding debian:Sectigo_Public_Server_Authentication_Root_R46.pem\n",
            "done.\n",
            "Setting up openjdk-8-jre:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for ca-certificates (20240203~22.04.1) ...\n",
            "Updating certificates in /etc/ssl/certs...\n",
            "0 added, 0 removed; done.\n",
            "Running hooks in /etc/ca-certificates/update.d...\n",
            "\n",
            "done.\n",
            "done.\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n"
          ]
        }
      ],
      "source": [
        "# Colab 셀 1: 라이브러리 설치\n",
        "# torch 및 torchtext의 호환되는 버전을 명시하여 설치\n",
        "# !pip uninstall -y torch torchtext torchvision torchaudio\n",
        "!pip install --upgrade torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 torchtext==0.18.0\n",
        "!pip install spacy konlpy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# konlpy 사용을 위한 자바 설치\n",
        "!apt-get install openjdk-8-jdk -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchtext.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsaRcd3-Tyzl",
        "outputId": "4ce80f4a-6244-4396-a8f3-afd146679534"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "0.18.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) JPype 관련 패키지 싹 제거\n",
        "!pip uninstall -y jpype JPype1 jpype1\n",
        "\n",
        "# 2) 자바 설치 (Colab용, JDK 17)\n",
        "!apt-get -y update\n",
        "!apt-get -y install openjdk-17-jdk-headless\n",
        "\n",
        "# 3) JPype1, konlpy 깔끔하게 재설치\n",
        "!pip install JPype1==1.4.1\n",
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcMKkwQBUOL_",
        "outputId": "bfc5861c-9b91-4716-8455-c40e92bec498"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping jpype as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: jpype1 1.6.0\n",
            "Uninstalling jpype1-1.6.0:\n",
            "  Successfully uninstalled jpype1-1.6.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,123 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,434 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,969 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,168 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,825 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,526 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,856 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Fetched 37.2 MB in 4s (9,392 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  openjdk-17-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-17-demo openjdk-17-source libnss-mdns fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-17-jdk-headless openjdk-17-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 120 MB of archives.\n",
            "After this operation, 272 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [48.3 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [71.3 MB]\n",
            "Fetched 120 MB in 5s (22.5 MB/s)\n",
            "Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
            "(Reading database ... 126011 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-17-jre-headless_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-17-jdk-headless_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "Collecting JPype1==1.4.1\n",
            "  Downloading JPype1-1.4.1.tar.gz (797 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.9/797.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1==1.4.1) (25.0)\n",
            "Building wheels for collected packages: JPype1\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for JPype1 (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for JPype1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for JPype1\n",
            "Failed to build JPype1\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (JPype1)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: konlpy in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Using cached jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Using cached jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (495 kB)\n",
            "Installing collected packages: JPype1\n",
            "Successfully installed JPype1-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LnvcWMegDnm"
      },
      "source": [
        "### 2. 데이터 다운로드 및 전처리\n",
        "\n",
        "[Tatoeba 프로젝트](http://www.manythings.org/anki/)의 소규모 영-한 병렬 코퍼스를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rwf70QxjgDnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19299010-a153-42d9-dd8d-4de076281bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-10 04:23:24--  http://www.manythings.org/anki/kor-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253046 (247K) [application/zip]\n",
            "Saving to: ‘kor-eng.zip’\n",
            "\n",
            "kor-eng.zip         100%[===================>] 247.12K  1.52MB/s    in 0.2s    \n",
            "\n",
            "2025-11-10 04:23:25 (1.52 MB/s) - ‘kor-eng.zip’ saved [253046/253046]\n",
            "\n",
            "Archive:  kor-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: kor.txt                 \n"
          ]
        }
      ],
      "source": [
        "# Colab 셀 2: 데이터 다운로드 및 압축 해제\n",
        "!wget http://www.manythings.org/anki/kor-eng.zip\n",
        "!unzip kor-eng.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmNn-phQgDnm"
      },
      "source": [
        "### 3. 기본 라이브러리 임포트 및 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "foUxq7tKgDnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030026a9-c7ba-4cf0-d967-106785fdf700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import spacy\n",
        "from konlpy.tag import Okt  # 한국어 형태소 분석기. (예: “사과를 먹었다” → [‘사과’, ‘를’, ‘먹었’, ‘다’])\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import io\n",
        "import os\n",
        "\n",
        "# 딥러닝이나 머신러닝에서는 모델 학습 과정에 무작위(random) 요소 많음: 가중치, 셔플, dropout ...\n",
        "# 매번 같은 결과를 재현위해서 시드 고정: “같은 코드 + 같은 데이터 + 같은 시드 → 같은 결과!”\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-61g-3bBgDnm"
      },
      "source": [
        "### 4. 토크나이저 정의\n",
        "\n",
        "영어는 `spaCy`, 한국어는 `Okt`를 사용해 토크나이저를 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jukjzCBzgDnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068acf89-7736-4543-c335-fc5acbb434c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'my', 'name', 'is', 'Kim', '.']\n",
            "['안녕하세요', ',', '제', '이름', '은', '김', '입니다', '.']\n"
          ]
        }
      ],
      "source": [
        "# 토크나이저 로드 및 정의\n",
        "import spacy\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "okt = Okt()\n",
        "\n",
        "def tokenize_en(text):\n",
        "  \"\"\"\n",
        "  spaCy를 사용한 영어 토크나이저\n",
        "  \"\"\"\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_ko(text):\n",
        "  \"\"\"\n",
        "  Okt를 사용한 한국어 토크나이저\n",
        "  \"\"\"\n",
        "  return okt.morphs(text)\n",
        "\n",
        "# 테스트\n",
        "print(tokenize_en(\"Hello, my name is Kim.\"))\n",
        "print(tokenize_ko(\"안녕하세요, 제 이름은 김입니다.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSK7JtxLgDnm"
      },
      "source": [
        "### 5. 데이터 로드 및 어휘장(Vocabulary) 구축\n",
        "\n",
        "다운로드한 `kor.txt` 파일(탭으로 구분)을 읽고, 영어와 한국어 어휘장을 만듦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "18ltLQcxgDnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5654262-eb06-4c0f-a17c-c3ca06ca4316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building English vocab...\n",
            "Building Korean vocab...\n",
            "English Vocab Size: 918\n",
            "Korean Vocab Size: 1014\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "\n",
        "# 데이터 로드 및 어휘장 구축\n",
        "DATA_PATH = 'kor.txt'\n",
        "MIN_FREQ = 5   #단어장에 포함될 최소 빈도\n",
        "\n",
        "# 특수 토큰 정의\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
        "\n",
        "# 영어/한국어 토큰 제너레이터\n",
        "def yield_en_tokens(data_path, tokenizer_en):\n",
        "  with io.open(data_path, encoding = 'utf-8') as f:\n",
        "    for line in f:\n",
        "      parts = line.strip().split('\\t')\n",
        "      if len(parts) >= 2:\n",
        "        yield tokenizer_en(parts[0])\n",
        "\n",
        "def yield_ko_tokens(data_path, tokenizer_ko):\n",
        "  with io.open(data_path, encoding = 'utf-8') as f:\n",
        "    for line in f:\n",
        "      parts = line.strip().split('\\t')\n",
        "      if len(parts) >= 2:\n",
        "        yield tokenizer_ko(parts[1])\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "print(\"Building English vocab...\")\n",
        "vocab_en = build_vocab_from_iterator(\n",
        "    yield_en_tokens(DATA_PATH, tokenize_en),\n",
        "    min_freq=MIN_FREQ,\n",
        "    specials=special_symbols,\n",
        "    special_first=True\n",
        ")\n",
        "vocab_en.set_default_index(UNK_IDX) # <unk> 토큰의 인덱스를 기본값으로 설정\n",
        "\n",
        "print(\"Building Korean vocab...\")\n",
        "vocab_ko = build_vocab_from_iterator(\n",
        "    yield_ko_tokens(DATA_PATH, tokenize_ko),\n",
        "    min_freq=MIN_FREQ,\n",
        "    specials=special_symbols,\n",
        "    special_first=True\n",
        ")\n",
        "vocab_ko.set_default_index(UNK_IDX)\n",
        "\n",
        "print(f\"English Vocab Size: {len(vocab_en)}\")\n",
        "print(f\"Korean Vocab Size: {len(vocab_ko)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MUrrDXtgDnn"
      },
      "source": [
        "### 6. Dataset 및 DataLoader 정의\n",
        "\n",
        "PyTorch의 `Dataset`과 `DataLoader`를 사용하여 데이터를 배치 단위로 처리할 수 있도록 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b5pOEZovgDnn"
      },
      "outputs": [],
      "source": [
        "# Dataset 정의\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class EngKorDataset(Dataset):\n",
        "  def __init__(self, data_path, vocab_en, vocab_ko, tokenizer_en, tokenizer_ko):\n",
        "    self.vocab_en = vocab_en\n",
        "    self.vocab_ko = vocab_ko\n",
        "    self.tokenizer_en = tokenizer_en\n",
        "    self.tokenizer_ko = tokenizer_ko\n",
        "    self.data = []\n",
        "\n",
        "    with io.open(data_path, encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "        parts = line.strip().split('\\t')\n",
        "        if len(parts) >= 2:\n",
        "          # [영어, 한국어] 쌍으로 저장\n",
        "          self.data.append((parts[0], parts[1]))\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      eng_text, kor_text = self.data[idx]\n",
        "      return eng_text, kor_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# Collate 함수 및 DataLoader 생성\n",
        "def collate_fn(batch):\n",
        "  \"\"\"\n",
        "    PyTorch의 DataLoader는 여러 샘플을 묶어 **하나의 배치(batch)**로 만듭니다.\n",
        "    하지만 NLP에서는 문장의 길이가 제각각이라 단순히 묶기 어렵습니다.\n",
        "    collate_fn은 각 문장을 토큰화 → 인덱스 변환 → 패딩(padding) 해서 동일한 길이로 만들어주는 함수\n",
        "  \"\"\"\n",
        "  src_batch, trg_batch = [], []\n",
        "  for src_sample, trg_sample in batch:\n",
        "      # 1. 토큰화\n",
        "      src_tokens = [tok for tok in tokenize_en(src_sample.lower())]\n",
        "      trg_tokens = [tok for tok in tokenize_ko(trg_sample)]\n",
        "\n",
        "      # 2. <sos> 및 <eos> 추가\n",
        "      src_with_eos = src_tokens + ['<eos>']\n",
        "      trg_with_sos_eos = ['<sos>'] + trg_tokens + ['<eos>']\n",
        "\n",
        "      # 3. 수치화 (Vocab 사용)\n",
        "      src_indices = [vocab_en[token] for token in src_with_eos]\n",
        "      trg_indices = [vocab_ko[token] for token in trg_with_sos_eos]\n",
        "\n",
        "      src_batch.append(torch.tensor(src_indices, dtype=torch.long))\n",
        "      trg_batch.append(torch.tensor(trg_indices, dtype=torch.long))\n",
        "\n",
        "  # 4. 패딩: RNN은 가변 길이 시퀀스를 받지만, 배치는 고정 길이여야 함\n",
        "  # pad_sequence는 (seq_len, batch_size) 형태의 텐서를 만듦\n",
        "  src_padded = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "  trg_padded = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
        "\n",
        "  return src_padded.to(device), trg_padded.to(device)\n",
        "\n",
        "\n",
        "# 데이터셋 분리 (학습 / 검증 / 테스트)\n",
        "full_dataset = EngKorDataset(DATA_PATH, vocab_en, vocab_ko, tokenize_en, tokenize_ko)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "valid_size = len(full_dataset) - train_size\n",
        "# Test 셋은 편의상 Valid 셋과 동일하게 사용 (원래는 분리해야 함)\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(full_dataset, [train_size, valid_size])\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# 데이터로더 테스트\n",
        "src_batch, trg_batch = next(iter(train_loader))\n",
        "print(f\"Source batch shape: {src_batch.shape}\") # (src_len, batch_size)\n",
        "print(f\"Target batch shape: {trg_batch.shape})\") # (trg_len, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Br2dkWfulc",
        "outputId": "0b1ad63c-fd9c-4916-9dde-ecaa5e7b231d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Source batch shape: torch.Size([14, 128])\n",
            "Target batch shape: torch.Size([17, 128]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2viigUXgDnn"
      },
      "source": [
        "### 7. Seq2Seq 모델 정의\n",
        "\n",
        "#### 7.1. Encoder (인코더)\n",
        "\n",
        "인코더는 입력 문장(영어)을 받아 하나의 '컨텍스트 벡터'(Context Vector)로 압축"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Encoder 정의\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "    super().__init__\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    # 1. 임베딩 층\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "    # 2. RNN 층\n",
        "    self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "\n",
        "    # 3. 드롭아웃\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self, src):\n",
        "\n",
        "    # 1. 임베딩\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "    # 2. RNN 통과\n",
        "    outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "    return hidden"
      ],
      "metadata": {
        "id": "6idtq1v-g_T6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHV0v_TZgDnn"
      },
      "source": [
        "#### 7.2. Decoder (디코더)\n",
        "\n",
        "디코더는 인코더의 컨텍스트 벡터와 이전 타임스텝의 예측 단어를 받아 다음 단어를 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5IMlL2fWgDnn"
      },
      "outputs": [],
      "source": [
        "# Decoder 정의\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # 1. 임베딩 층\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        # 2. RNN 층 (GRU 사용)\n",
        "        # 인코더와 동일한 파라미터를 가져야 함\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "\n",
        "        # 3. Fully Connected (Linear) 층\n",
        "        # RNN의 hidden state를 받아 어휘장 크기의 벡터로 변환\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # input: (batch_size) - 현재 time-step의 입력 단어 (t)\n",
        "        # hidden: (n_layers, batch_size, hid_dim) - 이전 time-step의 hidden state (t-1)\n",
        "\n",
        "        # 1. 입력 단어 임베딩\n",
        "        # (batch_size) -> (1, batch_size)로 변환 (GRU는 seq_len 차원이 필요)\n",
        "        input = input.unsqueeze(0)\n",
        "        # input: (1, batch_size)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded: (1, batch_size, emb_dim)\n",
        "\n",
        "        # 2. RNN 통과\n",
        "        # 디코더는 매 스텝마다 컨텍스트 벡터(hidden)를 업데이트\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "\n",
        "        # output: (1, batch_size, hid_dim)\n",
        "        # hidden: (n_layers, batch_size, hid_dim)\n",
        "\n",
        "        # 3. 예측 (Linear 층)\n",
        "        # (1, batch_size, hid_dim) -> (batch_size, output_dim)\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        # prediction: (batch_size, output_dim) - 한국어 어휘장 크기의 로짓(logit)\n",
        "\n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ftsDljgDnn"
      },
      "source": [
        "#### 7.3. Seq2Seq (모델 결합)\n",
        "\n",
        "인코더와 디코더를 결합하고, 'Teacher Forcing'을 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NjppUCAWgDnn"
      },
      "outputs": [],
      "source": [
        "# Seq2Seq 모델 정의\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "        # 인코더와 디코더의 hidden dim이 일치해야 함\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have same number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        # src: (src_len, batch_size)\n",
        "        # trg: (trg_len, batch_size)\n",
        "\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # 디코더의 출력을 저장할 텐서\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # 1. 인코더\n",
        "        # src 문장을 컨텍스트 벡터(hidden)로 압축\n",
        "        hidden = self.encoder(src)\n",
        "\n",
        "        # 2. 디코더\n",
        "        # 디코더의 첫 번째 입력은 <sos> 토큰\n",
        "        input = trg[0, :] # (batch_size)\n",
        "\n",
        "        # trg_len 만큼 반복 (i=0은 <sos>이므로 i=1부터 시작)\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            # 컨텍스트 벡터(hidden)와 현재 입력(input)을 디코더에 전달\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "\n",
        "            # 현재 스텝의 예측 저장\n",
        "            outputs[t] = output\n",
        "\n",
        "            # 'Teacher Forcing'\n",
        "            # 일정 확률로 실제 정답(trg[t])을 다음 입력으로 사용\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            # 가장 확률이 높은 단어의 인덱스\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            # Teacher Forcing이 켜져 있거나, <sos> 토큰이면 정답을, 아니면 모델의 예측을 다음 입력으로\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BLzetzvgDno"
      },
      "source": [
        "### 8. 모델 학습\n",
        "\n",
        "#### 8.1. 하이퍼파라미터 및 모델 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "2mZ4L_mPgDno",
        "outputId": "9f769ce0-3f4b-4df9-c507-744b6b653414"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "cannot assign module before Module.__init__() call",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3998782267.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 모델 인스턴스 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_EMB_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHID_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_DROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_EMB_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHID_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_DROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4048582367.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, emb_dim, hid_dim, n_layers, dropout)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 1. 임베딩 층\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 2. RNN 층\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m                     raise AttributeError(\n\u001b[0m\u001b[1;32m   1738\u001b[0m                         \"cannot assign module before Module.__init__() call\")\n\u001b[1;32m   1739\u001b[0m                 \u001b[0mremove_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: cannot assign module before Module.__init__() call"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn # Add this import for CrossEntropyLoss\n",
        "import torch # Add this import for torch.cuda.is_available() and torch.manual_seed\n",
        "\n",
        "# 모델 파라미터 및 초기화\n",
        "INPUT_DIM = len(vocab_en)\n",
        "OUTPUT_DIM = len(vocab_ko)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# 모델 인스턴스 생성\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "# 파라미터 수 확인\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "# 옵티마이저 (Adam)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# 손실 함수 (CrossEntropyLoss)\n",
        "# <pad> 토큰(인덱스 1)은 무시하도록 ignore_index 설정\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDFmSXi9gDno"
      },
      "source": [
        "#### 8.2. 학습 및 평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EphPsGXgDno"
      },
      "outputs": [],
      "source": [
        "# 학습 함수\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 1. 모델 순전파\n",
        "        # teacher_forcing_ratio = 0.5 (50% 확률로 Teacher Forcing 사용)\n",
        "        output = model(src, trg, 0.5)\n",
        "\n",
        "        # output: (trg_len, batch_size, output_dim)\n",
        "        # trg: (trg_len, batch_size)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        # 2. 손실 계산\n",
        "        # CrossEntropyLoss는 (N, C) 형태의 2D 입력과 (N) 형태의 1D 타겟을 기대함\n",
        "        # <sos> 토큰(인덱스 0)은 예측 대상이 아니므로 [1:] 부터 사용\n",
        "        output = output[1:].view(-1, output_dim) # ( (trg_len-1) * batch_size, output_dim )\n",
        "        trg = trg[1:].view(-1)                   # ( (trg_len-1) * batch_size )\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        # 3. 역전파 및 가중치 업데이트\n",
        "        loss.backward()\n",
        "\n",
        "        # 4. Gradient Clipping (폭주 방지)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B_IkUeIgDno"
      },
      "outputs": [],
      "source": [
        "# 평가 함수\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad(): # 그래디언트 계산 비활성화\n",
        "        for i, (src, trg) in enumerate(iterator):\n",
        "\n",
        "            # 1. 모델 순전파 (평가 시에는 Teacher Forcing 사용 안 함)\n",
        "            output = model(src, trg, 0) # teacher_forcing_ratio = 0\n",
        "\n",
        "            # 2. 손실 계산 (마찬가지로 <sos> 토큰 제외)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0yJCeTBgDno"
      },
      "source": [
        "#### 8.3. 실제 학습 실행 : 약 2분 시간 걸림\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKAqTLs3gDno"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# 학습 실행\n",
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# 시간 측정용\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # Validation loss가 가장 낮은 모델을 저장\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'seq2seq-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTEMRHmegDno"
      },
      "source": [
        "### 9. 결과: 모델 추론 (번역)\n",
        "\n",
        "학습된 모델을 사용하여 새로운 영어 문장을 한국어로 번역하는 함수를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ60A9hjgDno"
      },
      "outputs": [],
      "source": [
        "# 번역(추론) 함수\n",
        "def translate_sentence(sentence, model, vocab_en, vocab_ko, tokenizer_en, device, max_len=50):\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    # 1. 입력 문장 토큰화 및 전처리\n",
        "    tokens = [token.lower() for token in tokenizer_en(sentence)]\n",
        "    tokens = tokens + ['<eos>']\n",
        "    src_indexes = [vocab_en[token] for token in tokens]\n",
        "\n",
        "    # (src_len) -> (src_len, 1) : 배치 크기 1\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    # 2. 인코더\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(src_tensor)\n",
        "\n",
        "    # 3. 디코더\n",
        "    # <sos> 토큰으로 디코더 시작\n",
        "    trg_indexes = [SOS_IDX]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        # (1) -> (1, 1) : 배치 크기 1\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "        trg_tensor = trg_tensor.unsqueeze(0) # (1, 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(trg_tensor.squeeze(0), hidden)\n",
        "\n",
        "        # 가장 확률 높은 토큰 예측\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        # <eos> 토큰 만나면 종료\n",
        "        if pred_token == EOS_IDX:\n",
        "            break\n",
        "\n",
        "    # 4. 인덱스를 단어로 변환 (Vocabulary 사용)\n",
        "    trg_tokens = [vocab_ko.get_itos()[i] for i in trg_indexes]\n",
        "\n",
        "    # <sos> 제외하고 반환\n",
        "    return \" \".join(trg_tokens[1:-1]) # <sos>와 <eos> 제외"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpZ7ZV_tgDno"
      },
      "outputs": [],
      "source": [
        "# 예제: 번역 예제\n",
        "\n",
        "# 학습된 모델 로드\n",
        "model.load_state_dict(torch.load('seq2seq-model.pt'))\n",
        "\n",
        "# 검증 데이터셋에서 몇 개 샘플 뽑아서 테스트\n",
        "print(\"--- 번역 테스트 ---\")\n",
        "for i in range(5):\n",
        "    src, trg = valid_dataset[i]\n",
        "    translation = translate_sentence(src, model, vocab_en, vocab_ko, tokenize_en, device)\n",
        "\n",
        "    print(f\"원본 (Eng): {src}\")\n",
        "    print(f\"정답 (Kor): {trg}\")\n",
        "    print(f\"번역 (Model): {translation}\\n\")\n",
        "\n",
        "\n",
        "# 임의의 문장 테스트\n",
        "custom_sentence = \"A man is playing a guitar.\"\n",
        "translation = translate_sentence(custom_sentence, model, vocab_en, vocab_ko, tokenize_en, device)\n",
        "print(f\"원본 (Eng): {custom_sentence}\")\n",
        "print(f\"번역 (Model): {translation}\\n\")\n",
        "\n",
        "custom_sentence = \"I know it\"\n",
        "translation = translate_sentence(custom_sentence, model, vocab_en, vocab_ko, tokenize_en, device)\n",
        "print(f\"원본 (Eng): {custom_sentence}\")\n",
        "print(f\"번역 (Model): {translation}\\n\")\n",
        "\n",
        "custom_sentence = \"Hello\"\n",
        "translation = translate_sentence(custom_sentence, model, vocab_en, vocab_ko, tokenize_en, device)\n",
        "print(f\"원본 (Eng): {custom_sentence}\")\n",
        "print(f\"번역 (Model): {translation}\\n\")\n",
        "\n"
      ]
    }
  ]
}